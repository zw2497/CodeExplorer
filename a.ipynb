{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/03/13 17:19:38 Refreshing aws credentials for default\n",
      "2025/03/13 17:19:42 Successfully refreshed aws credentials for default\n"
     ]
    }
   ],
   "source": [
    "!ada credentials update --account=491718866258 --provider=isengard --role=Admin --profile=default --once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 17:19:42,216 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-03-13 17:19:42,217 - INFO - Loaded credentials from ~/.aws/credentials: Access Key ID = ASIA...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import boto3\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration\n",
    "AWS_REGION = \"us-east-1\"\n",
    "BEDROCK_MODEL = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "CODEBASE_PATH = \"/Users/wuzhiche/Workspace/ATE\"  # Default path\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Use boto3 to load credentials from ~/.aws/credentials default profile\n",
    "session = boto3.Session(profile_name=\"default\")\n",
    "credentials = session.get_credentials()\n",
    "if credentials:\n",
    "    logger.info(f\"Loaded credentials from ~/.aws/credentials: Access Key ID = {credentials.access_key[:4]}...\")\n",
    "else:\n",
    "    logger.warning(\"No credentials found in ~/.aws/credentials. Configure via AWS CLI ('aws configure').\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import List, TypedDict, Annotated\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class OpenFilesSchema(BaseModel):\n",
    "    \"\"\"Schema for the open_files tool.\"\"\"\n",
    "    file_paths: List[str] = Field(description=\"List of file paths to open, relative to the codebase root.\")\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: Annotated[List[HumanMessage | AIMessage | ToolMessage], add_messages]\n",
    "    all_files_opened: Annotated[List[str], operator.add]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool, StructuredTool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from typing import List\n",
    "\n",
    "def create_tools(filesystem):\n",
    "    \"\"\"Create and return the tools used by the chatbot.\"\"\"\n",
    "    \n",
    "    def open_files(file_paths: List[str]) -> str:\n",
    "        \"\"\"Open and return the contents of the specified files (up to 30000 chars each).\"\"\"\n",
    "        return filesystem.read_files(file_paths, max_chars=30000)\n",
    "    \n",
    "    tools = [\n",
    "        Tool(\n",
    "            name=\"get_file_structure\",\n",
    "            func=filesystem.get_file_structure,\n",
    "            description=\"Retrieve the file structure of the codebase.\"\n",
    "        ),\n",
    "        StructuredTool.from_function(\n",
    "            func=open_files,\n",
    "            name=\"open_files\",\n",
    "            description=\"Open and retrieve contents of files from the codebase.\",\n",
    "            args_schema=OpenFilesSchema\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return tools, [convert_to_openai_tool(t) for t in tools]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from typing import List\n",
    "from pathlib import Path\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class FileSystem:\n",
    "    def __init__(self, codebase_path: str):\n",
    "        self.path = Path(codebase_path)\n",
    "        self.files = self._list_files()\n",
    "\n",
    "    def _list_files(self) -> List[str]:\n",
    "        \"\"\"List all text files in the codebase.\"\"\"\n",
    "        text_extensions = {'.java', '.py', '.txt', '.js', '.cpp', '.h', '.yml', '.yaml', '.properties'}\n",
    "        return [str(f.relative_to(self.path)) for f in self.path.rglob(\"*\") \n",
    "                if f.is_file() and f.suffix.lower() in text_extensions]\n",
    "\n",
    "    def get_file_structure(self) -> str:\n",
    "        \"\"\"Generate a nested file structure with total size.\"\"\"\n",
    "        total_size = sum(f.stat().st_size for f in self.path.rglob(\"*\") if f.is_file()) / 1024\n",
    "        structure = f\"{self.path.name} ({total_size:.1f}KB, {len(self.files)} files)\\n\"\n",
    "        packages = {}\n",
    "        for file in self.files:\n",
    "            parts = file.split(os.sep)\n",
    "            pkg = \"/\".join(parts[:-1]) if len(parts) > 1 else \"\"\n",
    "            if pkg not in packages:\n",
    "                packages[pkg] = []\n",
    "            packages[pkg].append(parts[-1])\n",
    "        for pkg, files in sorted(packages.items()):\n",
    "            if pkg:\n",
    "                structure += f\"├── {pkg} ({len(files)} files)\\n\"\n",
    "            for file in sorted(files):\n",
    "                structure += f\"│   ├── {file}\\n\" if pkg else f\"├── {file}\\n\"\n",
    "        return structure.strip()\n",
    "\n",
    "    def read_files(self, file_paths: List[str], max_chars: int = 30000) -> str:\n",
    "        \"\"\"Read content of selected files, trimmed to max_chars, with path cleaning.\"\"\"\n",
    "        contents = {}\n",
    "        cleaned_paths = []\n",
    "\n",
    "        if isinstance(file_paths, str):\n",
    "            fp_cleaned = file_paths.replace('\\n', '').strip()\n",
    "            if fp_cleaned.startswith('[') and fp_cleaned.endswith(']'):\n",
    "                try:\n",
    "                    import ast\n",
    "                    cleaned_paths = ast.literal_eval(fp_cleaned)\n",
    "                    logger.debug(\"Converted stringified files list: %s\", cleaned_paths)\n",
    "                except (ValueError, SyntaxError) as e:\n",
    "                    logger.error(\"Failed to parse stringified file list: %s\", str(e))\n",
    "                    return \"No valid file contents retrieved.\"\n",
    "            else:\n",
    "                cleaned_paths = [fp_cleaned]\n",
    "        elif isinstance(file_paths, list):\n",
    "            cleaned_paths = file_paths\n",
    "\n",
    "        for fp in cleaned_paths:\n",
    "            fp_clean = fp.strip().strip(\"'\\\"[]\").strip()\n",
    "            fp_clean = ''.join(c for c in fp_clean if not c.isdigit()).strip().lstrip('. ').strip()\n",
    "            if not fp_clean or fp_clean == '/':\n",
    "                logger.warning(f\"Skipping invalid file path: {fp}\")\n",
    "                continue\n",
    "            full_path = self.path / fp_clean\n",
    "            if full_path.exists() and full_path.is_file():\n",
    "                try:\n",
    "                    with open(full_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        content = f.read()\n",
    "                        contents[fp_clean] = content[:max_chars] + (\"...\" if len(content) > max_chars else \"\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error reading file {fp_clean}: {str(e)}\")\n",
    "            else:\n",
    "                logger.warning(f\"File not found or not a file: {fp_clean}\")\n",
    "        return \"\\n\\n\".join([f\"{fp}:\\n{cont}\" for fp, cont in contents.items()]) if contents else \"No valid file contents retrieved.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 17:19:43,019 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n",
      "2025-03-13 17:19:43,019 - INFO - Loaded credentials from ~/.aws/credentials: Access Key ID = ASIA...\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any\n",
    "import logging\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from config import session, AWS_REGION, BEDROCK_MODEL\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def route_tools(state: ChatState):\n",
    "    if not state[\"messages\"]:\n",
    "        return END\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "class CodeExplorerChatbot:\n",
    "    def __init__(self, codebase_path: str):\n",
    "        self.fs = FileSystem(codebase_path)\n",
    "        self.checkpointer = MemorySaver()\n",
    "        self.llm = ChatBedrock(\n",
    "            model_id=BEDROCK_MODEL,\n",
    "            region_name=session.region_name or AWS_REGION,\n",
    "            model_kwargs={\"temperature\": 0.7, \"max_tokens\": 200000}\n",
    "        )\n",
    "        self.tools, openai_tools = create_tools(self.fs)\n",
    "        self.llm_with_tools = self.llm.bind_tools(openai_tools)\n",
    "        self._initialize_workflow()\n",
    "\n",
    "    def _initialize_workflow(self):\n",
    "        async def agent(state: ChatState, config) -> ChatState:\n",
    "            response = await self.llm_with_tools.ainvoke(state[\"messages\"], config)\n",
    "            return {\n",
    "                \"messages\": [response]\n",
    "            }\n",
    "    \n",
    "        def execute_tools(state: ChatState) -> ChatState:\n",
    "            messages = []\n",
    "            last_message = state[\"messages\"][-1]\n",
    "            all_files_opened = []\n",
    "            \n",
    "            for tool_call in last_message.tool_calls:\n",
    "                if tool_call[\"name\"] == \"open_files\":\n",
    "                    file_paths = tool_call[\"args\"].get(\"file_paths\", [])\n",
    "                    result = self.tools[1].func(file_paths)\n",
    "                    all_files_opened.extend(file_paths)\n",
    "                elif tool_call[\"name\"] == \"get_file_structure\":\n",
    "                    result = self.tools[0].func()\n",
    "                else:\n",
    "                    result = f\"Unknown tool: {tool_call['name']}\"\n",
    "                messages.append(ToolMessage(\n",
    "                    content=result, \n",
    "                    tool_call_id=tool_call[\"id\"]\n",
    "                ))\n",
    "            \n",
    "            return {\n",
    "                \"messages\": messages,\n",
    "                \"all_files_opened\": all_files_opened\n",
    "            }\n",
    "\n",
    "        workflow = StateGraph(ChatState)\n",
    "        workflow.add_node(\"agent\", agent)\n",
    "        workflow.add_node(\"tools\", execute_tools)\n",
    "        workflow.set_entry_point(\"agent\")\n",
    "        \n",
    "        workflow.add_conditional_edges(\n",
    "            \"agent\",\n",
    "            route_tools,\n",
    "            {\"tools\": \"tools\", END: END}\n",
    "        )\n",
    "        \n",
    "        workflow.add_edge(\"tools\", \"agent\")\n",
    "        self.app = workflow.compile(\n",
    "            checkpointer=self.checkpointer\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 17:19:44,298 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "a = CodeExplorerChatbot(CODEBASE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'type': 'text', 'text': 'Hello', 'index': 0}]\n",
      "[{'type': 'text', 'text': \"! I'm here to help you explore\", 'index': 0}]\n",
      "[{'type': 'text', 'text': ' the codebase. Woul', 'index': 0}]\n",
      "[{'type': 'text', 'text': 'd you like to see the file structure or', 'index': 0}]\n",
      "[{'type': 'text', 'text': ' open any specific files? I can', 'index': 0}]\n",
      "[{'type': 'text', 'text': ' assist you by using', 'index': 0}]\n",
      "[{'type': 'text', 'text': ' the available tools to retrieve information', 'index': 0}]\n",
      "[{'type': 'text', 'text': ' about the project.\\n\\nIs', 'index': 0}]\n",
      "[{'type': 'text', 'text': \" there anything specific you'\", 'index': 0}]\n",
      "[{'type': 'text', 'text': 'd like to know about the codebase', 'index': 0}]\n",
      "[{'type': 'text', 'text': '? I can:\\n1', 'index': 0}]\n",
      "[{'type': 'text', 'text': '. Show you the file structure', 'index': 0}]\n",
      "[{'type': 'text', 'text': ' using `get_file_', 'index': 0}]\n",
      "[{'type': 'text', 'text': 'structure`\\n2', 'index': 0}]\n",
      "[{'type': 'text', 'text': '. Open and view contents', 'index': 0}]\n",
      "[{'type': 'text', 'text': ' of specific files using `open', 'index': 0}]\n",
      "[{'type': 'text', 'text': '_files`\\n\\nJust', 'index': 0}]\n",
      "[{'type': 'text', 'text': \" let me know what you're\", 'index': 0}]\n",
      "[{'type': 'text', 'text': ' interested in!', 'index': 0}]\n"
     ]
    }
   ],
   "source": [
    "async for message_chunk, metadata in a.app.astream(\n",
    "    {\"messages\": [HumanMessage(content=\"hello\")]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if message_chunk.content:\n",
    "        print(message_chunk.content, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async for message_chunk, metadata in a.app.astream(\n",
    "    {\"messages\": [HumanMessage(content=\"what's the file structure\")]},\n",
    "    {\"configurable\": {\"thread_id\": \"1\"}},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    if message_chunk.content:\n",
    "        print(message_chunk.content, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.app.get_state({\"configurable\": {\"thread_id\": \"1\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 17:27:10,072 - INFO - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_aws import ChatBedrock\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    c: int\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "llm = ChatBedrock(\n",
    "            model_id=BEDROCK_MODEL,\n",
    "            region_name=session.region_name or AWS_REGION,\n",
    "            model_kwargs={\"temperature\": 0.7, \"max_tokens\": 200000}\n",
    "        )\n",
    "\n",
    "\n",
    "def chatbot(state: State, config):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])], \"c\": 1}\n",
    "\n",
    "def chatbot1(state: State, config):\n",
    "    return {}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"chatbot1\", chatbot1)\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", \"chatbot1\")\n",
    "graph_builder.set_finish_point(\"chatbot1\")\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 17:27:11,150 - INFO - Using Bedrock Invoke API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there! My name is Will.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 17:27:12,521 - INFO - The message received from Bedrock: Hi Will! It's nice to meet you. How are you doing today?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Will! It's nice to meet you. How are you doing today?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "user_input = \"Hi there! My name is Will.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(graph.get_state(config).values[\"c\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 15:14:34,649 - INFO - Using Bedrock Invoke API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there! what is my name?\n",
      "a {'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='8ed62c5e-5cc3-40a4-9be4-ff9e1dc86002'), AIMessage(content=\"Hi Will, it's nice to meet you! My name is Claude. I'm an AI assistant created by Anthropic.\", additional_kwargs={'usage': {'prompt_tokens': 15, 'completion_tokens': 29, 'total_tokens': 44}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 15, 'completion_tokens': 29, 'total_tokens': 44}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-9802fa31-61a0-409f-b333-5defafbca762-0', usage_metadata={'input_tokens': 15, 'output_tokens': 29, 'total_tokens': 44}), HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='1e1762dc-4f01-4a87-b09e-5ca830470645'), AIMessage(content=\"Hello again Will! As I mentioned, I'm Claude, an AI assistant. I'm happy to chat with you, answer questions, or try to help with any tasks you might have. Feel free to ask me about anything!\", additional_kwargs={'usage': {'prompt_tokens': 55, 'completion_tokens': 49, 'total_tokens': 104}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 55, 'completion_tokens': 49, 'total_tokens': 104}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-5ba9a67e-b5fe-4336-b241-e6a645940817-0', usage_metadata={'input_tokens': 55, 'output_tokens': 49, 'total_tokens': 104}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='1e253d90-bceb-49ac-8474-3033dfaa37c7'), AIMessage(content='You introduced yourself as Will, so your name is Will.', additional_kwargs={'usage': {'prompt_tokens': 115, 'completion_tokens': 15, 'total_tokens': 130}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 115, 'completion_tokens': 15, 'total_tokens': 130}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfb29375-de1c-47b5-bce6-9250395c8bc9-0', usage_metadata={'input_tokens': 115, 'output_tokens': 15, 'total_tokens': 130}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='8a509ca0-c42c-4911-93e2-0d3eb6f4ba77'), AIMessage(content='Your name is Will. You introduced yourself by saying \"Hi there! My name is Will.\"', additional_kwargs={'usage': {'prompt_tokens': 141, 'completion_tokens': 22, 'total_tokens': 163}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 141, 'completion_tokens': 22, 'total_tokens': 163}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-7f0dba7f-7928-458c-8d2d-e26dc6fe3650-0', usage_metadata={'input_tokens': 141, 'output_tokens': 22, 'total_tokens': 163}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='ffd3dd76-9232-4f21-83bf-185fd86b0d5b')]}\n",
      "b {'metadata': {'thread_id': '1', 'langgraph_step': 13, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:691d0756-d29b-3a2f-1da4-d6b1676bd8da'}, 'configurable': {'thread_id': '1', '__pregel_task_id': '691d0756-d29b-3a2f-1da4-d6b1676bd8da', '__pregel_send': functools.partial(<function PregelRunner.tick.<locals>.writer at 0x13510f2e0>, PregelExecutableTask(name='chatbot', input={'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='8ed62c5e-5cc3-40a4-9be4-ff9e1dc86002'), AIMessage(content=\"Hi Will, it's nice to meet you! My name is Claude. I'm an AI assistant created by Anthropic.\", additional_kwargs={'usage': {'prompt_tokens': 15, 'completion_tokens': 29, 'total_tokens': 44}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 15, 'completion_tokens': 29, 'total_tokens': 44}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-9802fa31-61a0-409f-b333-5defafbca762-0', usage_metadata={'input_tokens': 15, 'output_tokens': 29, 'total_tokens': 44}), HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='1e1762dc-4f01-4a87-b09e-5ca830470645'), AIMessage(content=\"Hello again Will! As I mentioned, I'm Claude, an AI assistant. I'm happy to chat with you, answer questions, or try to help with any tasks you might have. Feel free to ask me about anything!\", additional_kwargs={'usage': {'prompt_tokens': 55, 'completion_tokens': 49, 'total_tokens': 104}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 55, 'completion_tokens': 49, 'total_tokens': 104}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-5ba9a67e-b5fe-4336-b241-e6a645940817-0', usage_metadata={'input_tokens': 55, 'output_tokens': 49, 'total_tokens': 104}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='1e253d90-bceb-49ac-8474-3033dfaa37c7'), AIMessage(content='You introduced yourself as Will, so your name is Will.', additional_kwargs={'usage': {'prompt_tokens': 115, 'completion_tokens': 15, 'total_tokens': 130}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 115, 'completion_tokens': 15, 'total_tokens': 130}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfb29375-de1c-47b5-bce6-9250395c8bc9-0', usage_metadata={'input_tokens': 115, 'output_tokens': 15, 'total_tokens': 130}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='8a509ca0-c42c-4911-93e2-0d3eb6f4ba77'), AIMessage(content='Your name is Will. You introduced yourself by saying \"Hi there! My name is Will.\"', additional_kwargs={'usage': {'prompt_tokens': 141, 'completion_tokens': 22, 'total_tokens': 163}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 141, 'completion_tokens': 22, 'total_tokens': 163}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-7f0dba7f-7928-458c-8d2d-e26dc6fe3650-0', usage_metadata={'input_tokens': 141, 'output_tokens': 22, 'total_tokens': 163}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='ffd3dd76-9232-4f21-83bf-185fd86b0d5b')]}, proc=<langgraph.utils.runnable.RunnableSeq object at 0x1379dae30>, writes=deque([]), config={'metadata': {'thread_id': '1', 'langgraph_step': 13, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:691d0756-d29b-3a2f-1da4-d6b1676bd8da'}, 'configurable': {'thread_id': '1', '__pregel_task_id': '691d0756-d29b-3a2f-1da4-d6b1676bd8da', '__pregel_send': functools.partial(<function local_write at 0x1157bedd0>, <built-in method extend of collections.deque object at 0x146452920>, dict_keys(['__start__', 'chatbot'])), '__pregel_read': functools.partial(<function local_read at 0x1157bed40>, 13, {'v': 1, 'ts': '2025-03-13T07:14:34.646849+00:00', 'id': '1efffdad-1049-6d0c-800c-651092ba5973', 'channel_values': {'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='8ed62c5e-5cc3-40a4-9be4-ff9e1dc86002'), AIMessage(content=\"Hi Will, it's nice to meet you! My name is Claude. I'm an AI assistant created by Anthropic.\", additional_kwargs={'usage': {'prompt_tokens': 15, 'completion_tokens': 29, 'total_tokens': 44}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 15, 'completion_tokens': 29, 'total_tokens': 44}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-9802fa31-61a0-409f-b333-5defafbca762-0', usage_metadata={'input_tokens': 15, 'output_tokens': 29, 'total_tokens': 44}), HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='1e1762dc-4f01-4a87-b09e-5ca830470645'), AIMessage(content=\"Hello again Will! As I mentioned, I'm Claude, an AI assistant. I'm happy to chat with you, answer questions, or try to help with any tasks you might have. Feel free to ask me about anything!\", additional_kwargs={'usage': {'prompt_tokens': 55, 'completion_tokens': 49, 'total_tokens': 104}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 55, 'completion_tokens': 49, 'total_tokens': 104}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-5ba9a67e-b5fe-4336-b241-e6a645940817-0', usage_metadata={'input_tokens': 55, 'output_tokens': 49, 'total_tokens': 104}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='1e253d90-bceb-49ac-8474-3033dfaa37c7'), AIMessage(content='You introduced yourself as Will, so your name is Will.', additional_kwargs={'usage': {'prompt_tokens': 115, 'completion_tokens': 15, 'total_tokens': 130}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 115, 'completion_tokens': 15, 'total_tokens': 130}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfb29375-de1c-47b5-bce6-9250395c8bc9-0', usage_metadata={'input_tokens': 115, 'output_tokens': 15, 'total_tokens': 130}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='8a509ca0-c42c-4911-93e2-0d3eb6f4ba77'), AIMessage(content='Your name is Will. You introduced yourself by saying \"Hi there! My name is Will.\"', additional_kwargs={'usage': {'prompt_tokens': 141, 'completion_tokens': 22, 'total_tokens': 163}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 141, 'completion_tokens': 22, 'total_tokens': 163}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-7f0dba7f-7928-458c-8d2d-e26dc6fe3650-0', usage_metadata={'input_tokens': 141, 'output_tokens': 22, 'total_tokens': 163}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='ffd3dd76-9232-4f21-83bf-185fd86b0d5b')], 'start:chatbot': '__start__'}, 'channel_versions': {'__start__': '00000000000000000000000000000014.0.9266204170180341', 'messages': '00000000000000000000000000000014.0.052483917248513645', 'start:chatbot': '00000000000000000000000000000014.0.7037513666238997', 'chatbot': '00000000000000000000000000000014.0.7280495579109323'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000013.0.164994199634642'}, 'chatbot': {'start:chatbot': '00000000000000000000000000000011.0.6702916624508267'}}, 'pending_sends': []}, {'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x146469000>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x1464685c0>, 'chatbot': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x146468740>, 'branch:__start__:__self__:chatbot': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x146468080>, 'branch:chatbot:__self__:chatbot': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x146468580>, 'start:chatbot': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x146468700>}, {}, PregelTaskWrites(path=('__pregel_pull', 'chatbot'), name='chatbot', writes=deque([]), triggers=['start:chatbot']), {'tags': [], 'metadata': ChainMap({'thread_id': '1'}), 'callbacks': None, 'recursion_limit': 25, 'configurable': {'thread_id': '1'}}), '__pregel_store': None, '__pregel_checkpointer': <langgraph.checkpoint.memory.InMemorySaver object at 0x1352ffdc0>, 'checkpoint_map': {'': '1efffdad-1049-6d0c-800c-651092ba5973'}, 'checkpoint_id': None, 'checkpoint_ns': 'chatbot:691d0756-d29b-3a2f-1da4-d6b1676bd8da', '__pregel_scratchpad': PregelScratchpad(call_counter=<method-wrapper '__next__' of itertools.count object at 0x13618f840>, interrupt_counter=<method-wrapper '__next__' of itertools.count object at 0x14645e080>, resume=[], null_resume=None, _consume_null_resume=<function _scratchpad.<locals>.<lambda> at 0x13533bd00>, subgraph_counter=<method-wrapper '__next__' of itertools.count object at 0x14645db40>), '__pregel_previous': None}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x1352fd0c0>, 'run_name': 'chatbot'}, triggers=['start:chatbot'], retry_policy=None, cache_policy=None, id='691d0756-d29b-3a2f-1da4-d6b1676bd8da', path=('__pregel_pull', 'chatbot'), scheduled=False, writers=[ChannelWrite<...,chatbot>(tags=['langsmith:hidden'], recurse=True, explode_args=False, func_accepts_config=True, func_accepts={}, writes=[ChannelWriteTupleEntry(mapper=<function CompiledStateGraph.attach_node.<locals>._get_updates at 0x13533b520>, value=<object object at 0x10632ef30>), ChannelWriteEntry(channel='chatbot', value='chatbot', skip_none=False, mapper=None)], require_at_least_one_of=None), _route(tags=None, recurse=True, explode_args=False, func_accepts_config=True, func_accepts={}, _is_channel_writer=True)], subgraphs=[])), '__pregel_read': functools.partial(<function local_read at 0x1157bed40>, 13, {'v': 1, 'ts': '2025-03-13T07:14:34.646849+00:00', 'id': '1efffdad-1049-6d0c-800c-651092ba5973', 'channel_values': {'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='8ed62c5e-5cc3-40a4-9be4-ff9e1dc86002'), AIMessage(content=\"Hi Will, it's nice to meet you! My name is Claude. I'm an AI assistant created by Anthropic.\", additional_kwargs={'usage': {'prompt_tokens': 15, 'completion_tokens': 29, 'total_tokens': 44}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 15, 'completion_tokens': 29, 'total_tokens': 44}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-9802fa31-61a0-409f-b333-5defafbca762-0', usage_metadata={'input_tokens': 15, 'output_tokens': 29, 'total_tokens': 44}), HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='1e1762dc-4f01-4a87-b09e-5ca830470645'), AIMessage(content=\"Hello again Will! As I mentioned, I'm Claude, an AI assistant. I'm happy to chat with you, answer questions, or try to help with any tasks you might have. Feel free to ask me about anything!\", additional_kwargs={'usage': {'prompt_tokens': 55, 'completion_tokens': 49, 'total_tokens': 104}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 55, 'completion_tokens': 49, 'total_tokens': 104}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-5ba9a67e-b5fe-4336-b241-e6a645940817-0', usage_metadata={'input_tokens': 55, 'output_tokens': 49, 'total_tokens': 104}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='1e253d90-bceb-49ac-8474-3033dfaa37c7'), AIMessage(content='You introduced yourself as Will, so your name is Will.', additional_kwargs={'usage': {'prompt_tokens': 115, 'completion_tokens': 15, 'total_tokens': 130}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 115, 'completion_tokens': 15, 'total_tokens': 130}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfb29375-de1c-47b5-bce6-9250395c8bc9-0', usage_metadata={'input_tokens': 115, 'output_tokens': 15, 'total_tokens': 130}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='8a509ca0-c42c-4911-93e2-0d3eb6f4ba77'), AIMessage(content='Your name is Will. You introduced yourself by saying \"Hi there! My name is Will.\"', additional_kwargs={'usage': {'prompt_tokens': 141, 'completion_tokens': 22, 'total_tokens': 163}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 141, 'completion_tokens': 22, 'total_tokens': 163}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-7f0dba7f-7928-458c-8d2d-e26dc6fe3650-0', usage_metadata={'input_tokens': 141, 'output_tokens': 22, 'total_tokens': 163}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='ffd3dd76-9232-4f21-83bf-185fd86b0d5b')], 'start:chatbot': '__start__'}, 'channel_versions': {'__start__': '00000000000000000000000000000014.0.9266204170180341', 'messages': '00000000000000000000000000000014.0.052483917248513645', 'start:chatbot': '00000000000000000000000000000014.0.7037513666238997', 'chatbot': '00000000000000000000000000000014.0.7280495579109323'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000013.0.164994199634642'}, 'chatbot': {'start:chatbot': '00000000000000000000000000000011.0.6702916624508267'}}, 'pending_sends': []}, {'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x146469000>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x1464685c0>, 'chatbot': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x146468740>, 'branch:__start__:__self__:chatbot': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x146468080>, 'branch:chatbot:__self__:chatbot': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x146468580>, 'start:chatbot': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x146468700>}, {}, PregelTaskWrites(path=('__pregel_pull', 'chatbot'), name='chatbot', writes=deque([]), triggers=['start:chatbot']), {'tags': [], 'metadata': ChainMap({'thread_id': '1'}), 'callbacks': None, 'recursion_limit': 25, 'configurable': {'thread_id': '1'}}), '__pregel_store': None, '__pregel_checkpointer': <langgraph.checkpoint.memory.InMemorySaver object at 0x1352ffdc0>, 'checkpoint_map': {'': '1efffdad-1049-6d0c-800c-651092ba5973'}, 'checkpoint_id': None, 'checkpoint_ns': 'chatbot:691d0756-d29b-3a2f-1da4-d6b1676bd8da', '__pregel_scratchpad': PregelScratchpad(call_counter=<method-wrapper '__next__' of itertools.count object at 0x13618f840>, interrupt_counter=<method-wrapper '__next__' of itertools.count object at 0x14645e080>, resume=[], null_resume=None, _consume_null_resume=<function _scratchpad.<locals>.<lambda> at 0x13533bd00>, subgraph_counter=<method-wrapper '__next__' of itertools.count object at 0x14645db40>), '__pregel_previous': None, '__pregel_call': functools.partial(<function PregelRunner.tick.<locals>.call at 0x13533b6d0>, PregelExecutableTask(name='chatbot', input={'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='8ed62c5e-5cc3-40a4-9be4-ff9e1dc86002'), AIMessage(content=\"Hi Will, it's nice to meet you! My name is Claude. I'm an AI assistant created by Anthropic.\", additional_kwargs={'usage': {'prompt_tokens': 15, 'completion_tokens': 29, 'total_tokens': 44}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 15, 'completion_tokens': 29, 'total_tokens': 44}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-9802fa31-61a0-409f-b333-5defafbca762-0', usage_metadata={'input_tokens': 15, 'output_tokens': 29, 'total_tokens': 44}), HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='1e1762dc-4f01-4a87-b09e-5ca830470645'), AIMessage(content=\"Hello again Will! As I mentioned, I'm Claude, an AI assistant. I'm happy to chat with you, answer questions, or try to help with any tasks you might have. Feel free to ask me about anything!\", additional_kwargs={'usage': {'prompt_tokens': 55, 'completion_tokens': 49, 'total_tokens': 104}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 55, 'completion_tokens': 49, 'total_tokens': 104}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-5ba9a67e-b5fe-4336-b241-e6a645940817-0', usage_metadata={'input_tokens': 55, 'output_tokens': 49, 'total_tokens': 104}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='1e253d90-bceb-49ac-8474-3033dfaa37c7'), AIMessage(content='You introduced yourself as Will, so your name is Will.', additional_kwargs={'usage': {'prompt_tokens': 115, 'completion_tokens': 15, 'total_tokens': 130}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 115, 'completion_tokens': 15, 'total_tokens': 130}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfb29375-de1c-47b5-bce6-9250395c8bc9-0', usage_metadata={'input_tokens': 115, 'output_tokens': 15, 'total_tokens': 130}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='8a509ca0-c42c-4911-93e2-0d3eb6f4ba77'), AIMessage(content='Your name is Will. You introduced yourself by saying \"Hi there! My name is Will.\"', additional_kwargs={'usage': {'prompt_tokens': 141, 'completion_tokens': 22, 'total_tokens': 163}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 141, 'completion_tokens': 22, 'total_tokens': 163}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-7f0dba7f-7928-458c-8d2d-e26dc6fe3650-0', usage_metadata={'input_tokens': 141, 'output_tokens': 22, 'total_tokens': 163}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='ffd3dd76-9232-4f21-83bf-185fd86b0d5b')]}, proc=<langgraph.utils.runnable.RunnableSeq object at 0x1379dae30>, writes=deque([]), config={'metadata': {'thread_id': '1', 'langgraph_step': 13, 'langgraph_node': 'chatbot', 'langgraph_triggers': ['start:chatbot'], 'langgraph_path': ('__pregel_pull', 'chatbot'), 'langgraph_checkpoint_ns': 'chatbot:691d0756-d29b-3a2f-1da4-d6b1676bd8da'}, 'configurable': {'thread_id': '1', '__pregel_task_id': '691d0756-d29b-3a2f-1da4-d6b1676bd8da', '__pregel_send': functools.partial(<function local_write at 0x1157bedd0>, <built-in method extend of collections.deque object at 0x146452920>, dict_keys(['__start__', 'chatbot'])), '__pregel_read': functools.partial(<function local_read at 0x1157bed40>, 13, {'v': 1, 'ts': '2025-03-13T07:14:34.646849+00:00', 'id': '1efffdad-1049-6d0c-800c-651092ba5973', 'channel_values': {'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='8ed62c5e-5cc3-40a4-9be4-ff9e1dc86002'), AIMessage(content=\"Hi Will, it's nice to meet you! My name is Claude. I'm an AI assistant created by Anthropic.\", additional_kwargs={'usage': {'prompt_tokens': 15, 'completion_tokens': 29, 'total_tokens': 44}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 15, 'completion_tokens': 29, 'total_tokens': 44}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-9802fa31-61a0-409f-b333-5defafbca762-0', usage_metadata={'input_tokens': 15, 'output_tokens': 29, 'total_tokens': 44}), HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='1e1762dc-4f01-4a87-b09e-5ca830470645'), AIMessage(content=\"Hello again Will! As I mentioned, I'm Claude, an AI assistant. I'm happy to chat with you, answer questions, or try to help with any tasks you might have. Feel free to ask me about anything!\", additional_kwargs={'usage': {'prompt_tokens': 55, 'completion_tokens': 49, 'total_tokens': 104}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 55, 'completion_tokens': 49, 'total_tokens': 104}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-5ba9a67e-b5fe-4336-b241-e6a645940817-0', usage_metadata={'input_tokens': 55, 'output_tokens': 49, 'total_tokens': 104}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='1e253d90-bceb-49ac-8474-3033dfaa37c7'), AIMessage(content='You introduced yourself as Will, so your name is Will.', additional_kwargs={'usage': {'prompt_tokens': 115, 'completion_tokens': 15, 'total_tokens': 130}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 115, 'completion_tokens': 15, 'total_tokens': 130}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-cfb29375-de1c-47b5-bce6-9250395c8bc9-0', usage_metadata={'input_tokens': 115, 'output_tokens': 15, 'total_tokens': 130}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='8a509ca0-c42c-4911-93e2-0d3eb6f4ba77'), AIMessage(content='Your name is Will. You introduced yourself by saying \"Hi there! My name is Will.\"', additional_kwargs={'usage': {'prompt_tokens': 141, 'completion_tokens': 22, 'total_tokens': 163}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 141, 'completion_tokens': 22, 'total_tokens': 163}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-7f0dba7f-7928-458c-8d2d-e26dc6fe3650-0', usage_metadata={'input_tokens': 141, 'output_tokens': 22, 'total_tokens': 163}), HumanMessage(content='Hi there! what is my name?', additional_kwargs={}, response_metadata={}, id='ffd3dd76-9232-4f21-83bf-185fd86b0d5b')], 'start:chatbot': '__start__'}, 'channel_versions': {'__start__': '00000000000000000000000000000014.0.9266204170180341', 'messages': '00000000000000000000000000000014.0.052483917248513645', 'start:chatbot': '00000000000000000000000000000014.0.7037513666238997', 'chatbot': '00000000000000000000000000000014.0.7280495579109323'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000013.0.164994199634642'}, 'chatbot': {'start:chatbot': '00000000000000000000000000000011.0.6702916624508267'}}, 'pending_sends': []}, {'messages': <langgraph.channels.binop.BinaryOperatorAggregate object at 0x146469000>, '__start__': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x1464685c0>, 'chatbot': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x146468740>, 'branch:__start__:__self__:chatbot': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x146468080>, 'branch:chatbot:__self__:chatbot': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x146468580>, 'start:chatbot': <langgraph.channels.ephemeral_value.EphemeralValue object at 0x146468700>}, {}, PregelTaskWrites(path=('__pregel_pull', 'chatbot'), name='chatbot', writes=deque([]), triggers=['start:chatbot']), {'tags': [], 'metadata': ChainMap({'thread_id': '1'}), 'callbacks': None, 'recursion_limit': 25, 'configurable': {'thread_id': '1'}}), '__pregel_store': None, '__pregel_checkpointer': <langgraph.checkpoint.memory.InMemorySaver object at 0x1352ffdc0>, 'checkpoint_map': {'': '1efffdad-1049-6d0c-800c-651092ba5973'}, 'checkpoint_id': None, 'checkpoint_ns': 'chatbot:691d0756-d29b-3a2f-1da4-d6b1676bd8da', '__pregel_scratchpad': PregelScratchpad(call_counter=<method-wrapper '__next__' of itertools.count object at 0x13618f840>, interrupt_counter=<method-wrapper '__next__' of itertools.count object at 0x14645e080>, resume=[], null_resume=None, _consume_null_resume=<function _scratchpad.<locals>.<lambda> at 0x13533bd00>, subgraph_counter=<method-wrapper '__next__' of itertools.count object at 0x14645db40>), '__pregel_previous': None}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x1352fd0c0>, 'run_name': 'chatbot'}, triggers=['start:chatbot'], retry_policy=None, cache_policy=None, id='691d0756-d29b-3a2f-1da4-d6b1676bd8da', path=('__pregel_pull', 'chatbot'), scheduled=False, writers=[ChannelWrite<...,chatbot>(tags=['langsmith:hidden'], recurse=True, explode_args=False, func_accepts_config=True, func_accepts={}, writes=[ChannelWriteTupleEntry(mapper=<function CompiledStateGraph.attach_node.<locals>._get_updates at 0x13533b520>, value=<object object at 0x10632ef30>), ChannelWriteEntry(channel='chatbot', value='chatbot', skip_none=False, mapper=None)], require_at_least_one_of=None), _route(tags=None, recurse=True, explode_args=False, func_accepts_config=True, func_accepts={}, _is_channel_writer=True)], subgraphs=[]))}, 'callbacks': <langchain_core.callbacks.manager.CallbackManager object at 0x135aab3a0>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 15:14:35,694 - INFO - The message received from Bedrock: Will, you've introduced yourself as Will multiple times now. I remember that your name is Will.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Will, you've introduced yourself as Will multiple times now. I remember that your name is Will.\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "user_input = \"Hi there! what is my name?\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'messages': [HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='066597c1-1e50-4cdd-abb8-dcd68df6204c'), AIMessage(content=\"Hi Will, it's nice to meet you! I'm Claude, an AI assistant created by Anthropic. How are you doing today?\", additional_kwargs={'usage': {'prompt_tokens': 15, 'completion_tokens': 32, 'total_tokens': 47}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 15, 'completion_tokens': 32, 'total_tokens': 47}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-1e36f270-a547-44d9-855a-ad18875b454b-0', usage_metadata={'input_tokens': 15, 'output_tokens': 32, 'total_tokens': 47}), HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='be447d32-d54e-4dbb-91da-54ccd7a3bf1c'), AIMessage(content=\"Hello again Will! I'm doing well, thanks for asking. As an AI, I don't experience emotions quite the same way humans do, but I enjoy our conversations. How has your day been going so far?\", additional_kwargs={'usage': {'prompt_tokens': 58, 'completion_tokens': 47, 'total_tokens': 105}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 58, 'completion_tokens': 47, 'total_tokens': 105}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-7ee4c6a4-c6b3-4e5c-8d50-b7ab0901c14c-0', usage_metadata={'input_tokens': 58, 'output_tokens': 47, 'total_tokens': 105})]}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efffdae-228c-6306-8004-aac83c87e4db'}}, metadata={'source': 'loop', 'writes': {'chatbot': {'messages': [AIMessage(content=\"Hello again Will! I'm doing well, thanks for asking. As an AI, I don't experience emotions quite the same way humans do, but I enjoy our conversations. How has your day been going so far?\", additional_kwargs={'usage': {'prompt_tokens': 58, 'completion_tokens': 47, 'total_tokens': 105}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, response_metadata={'usage': {'prompt_tokens': 58, 'completion_tokens': 47, 'total_tokens': 105}, 'stop_reason': 'end_turn', 'model_id': 'anthropic.claude-3-sonnet-20240229-v1:0'}, id='run-7ee4c6a4-c6b3-4e5c-8d50-b7ab0901c14c-0', usage_metadata={'input_tokens': 58, 'output_tokens': 47, 'total_tokens': 105})]}}, 'thread_id': '1', 'step': 4, 'parents': {}}, created_at='2025-03-13T07:15:03.405019+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1efffdae-16a7-6af4-8003-309da57d4d27'}}, tasks=())"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
